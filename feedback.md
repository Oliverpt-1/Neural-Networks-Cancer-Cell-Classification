# Project 2 feedback

### Rubric

 - Data exploration: 12.5/15
 - Model choice/exploration: 10/10
 - Code: 8/10
 - Report:

     **Content**

     - Objective description: 4/5
     - Method description: 10/10
     - Analysis: 10/10
     - Results: 8/10
     - Ethics: 2/5
     - Writing clarity: 5/5

 - Total: 69.5/80


#### Dr. Kuchera's Notes:

Overall nice work. Simply being a bit more careful with data exploration and status of codebase would have improved your grade without much additional work.


**Data exploration:**

Please upload as `.txt` so I don't have to download the file. 

Overall good work investigating the data. Presentation is missing your conlcusions of looking at this information... e.g. what scaling methods will you use for what features? You mention handling outliers, but what does this mean? Your paper didn't clarify some of these points either.

**Model choice/exploration**


**Code:**

Overall easy to read, find, etc. I wasn't sure was `PyTorch.ipynb` vs `pyTorch.ipynb` were... code doesn't look the same. Better in-code documentation, filenames, or maybe readme instructions would help me correlate torch code to results in paper.

**REPORT:**

**Objective description**

Overall nice job, but missing some information about the data itself when describing the learning task.


**Method description**

Really, really nice.


**Analysis**

Great

**Results**

Overall really nice. I'm not confident your models have the exact same test set, or the exact same loss function, making direct comparisons a bit misleading.

ALso, I'm a bit confused about the feature importance analysis... how are there weight values associated with each feature? Doesn't seem to follow the math of a neural network? 

**Ethics**

Weak ethics section, make sure to cite work in this field.

**Writing**

Clear, easy to understand.
